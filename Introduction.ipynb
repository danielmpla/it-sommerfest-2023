{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# IT-Sommerfest 2023\n",
    "\n",
    "## Einführung in maschinelles Lernen\n",
    "*Disclaimer:* Die Animationen und der Code wurden größtenteils aus dem Buch \"Neural Networks from Scratch\" entnommen. Weitere Informationen zum Buch finden Sie unter [nnfs.io](https://nnfs.io).\n",
    "\n",
    "### Einführung in das Problem\n",
    "\n",
    "Im Folgenden wollen wir Schritt für Schritt ein neuronales Netz entwickeln, welches aus Daten lernen kann. Um eine Vorstellung zu bekommen, womit das neuronale Netz arbeitet und warum es aussieht wie es aussieht sollen zuerst die Daten gezeigt werden, die gelernt werden. Hierbei wollen wir uns dem MNIST-Datensatz bedienen. Dieser Datensatz kann im Bereich des maschinellen Lernens als `Hello World` Beispiel angesehen werden. Es handelt sich hierbei um handschriftlich geschriebene Ziffern von $0$ bis $9$. Dieser Datensatz eignet sich besonders gut für Einsteiger, da hier bereits einige Vorverarbeitungsschritte durchgeführt wurden sind, die es uns ermöglichen die Daten sofort zu verwenden. Dazu zählt unter anderem die klare Abhebung der Ziffern von dem Untergrund. Alle Ziffern sind korrekt ausgerichtet, zentriert und der Schwerpunkt befindet sich in der Mitte. Die Ziffern liegen in Schwarz-Weiß in 28x28 Pixeln vor. Es folgt ein Beispiel der Daten:\n",
    "\n",
    "![](resources/mnist.jpg)\n",
    "Quelle: https://sefiks.com/2018/08/15/from-neural-networks-to-deep-learning/\n",
    "\n",
    "Wie wir sehen, wird hier eine $8$ abgebildet. Damit der Computer diese und weitere lernen kann muss die Zahl in ein Format umgewandelt werden, welches maschinenlesbar ist. Dies wird im zweiten Schritt symbolisiert. Da die Ziffer in Graustufen vorliegt haben wir Werte zwischen $0$ und $255$, wobei $0$ schwarz ist und $255$ weiß. Im letzten Schritt ist zu sehen, dass diese Daten in ein neuronales Netz gegeben werden. Dieses wollen wir uns im nächsten Schritt ansehen, wenn auch mit anderen Daten.\n",
    "\n",
    "### neuronale Netze\n",
    "\n",
    "Ein neuronales Netz besteht aus mehreren Neuronen, die sich in Schichten befinden. Jedes Neuron empfängt Daten. Diese werden gewichtet und mit einem Bias versehen. Bei jedem Netz kann die Anzahl der Schichten, Neuronen, Gewichte und Biases unterschiedlich sein, wie die folgende Animation veranschaulicht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/Ls1dJqZtI7w?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/Ls1dJqZtI7w?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.490013100Z",
     "start_time": "2023-06-21T13:31:45.553797300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ein Neuron\n",
    "\n",
    "Als grundlegende Basis für unsere neuronalen Netze dienen die Neuronen. Die ursprüngliche Idee war es die Neuronen im Gehirn möglichst gut nachzubilden. Wie sich aber herausgestellt hat, ist dies nicht gut gelungen. Trotzdem bilden sie die Grundlage für die meisten der heutigen intelligenten Maschinen. Jedes Neuron hat erhält Daten als Input ($x_0, x_1, ... x_i$), welche einzeln mit einem dazugehörigen Gewicht ($w_0, w_1, ..., w_i$) multipliziert werden. Die gewichteten Eingaben werden dann aufsummiert und mit einem Bias bzw. Aktivierungsschwelle ($\\theta$) versehen. Üblicherweise folgt noch ein Aktivierungsfunktion, die den Output in einem bestimmten Wertebereich beschränkt. Außerdem sorgen nicht-lineare Aktivierungsfunktionen dafür, dass wir komplexe Daten lernen können. Schematisch könnte ein Neuron wie folgt aussehen:\n",
    "\n",
    "![](resources/neuron.png)\n",
    "Quelle: https://de.wikipedia.org/wiki/Datei:Computer.Science.AI.Neuron.svg\n",
    "\n",
    "Die dazu entsprechende Formel sieht wie folgt aus: $Y = X \\cdot w + \\theta$. Woran erinnert dies Formel?\n",
    "\n",
    "Damit können wir nun das erste Neuron implementieren:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.496005900Z",
     "start_time": "2023-06-21T13:31:45.595792800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2\n",
    "\n",
    "output = (inputs[0] * weights[0] +\n",
    "          inputs[1] * weights[1] +\n",
    "          inputs[2] * weights[2] +\n",
    "          bias)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vbeanwfm0Q4?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vbeanwfm0Q4?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.499006200Z",
     "start_time": "2023-06-21T13:31:45.643795100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Aufgabe 1:** Erstellen Sie ein Neuron für 4 Eingabewerte mit den folgenden Eingaben und Gewichten!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.499006200Z",
     "start_time": "2023-06-21T13:31:45.739793700Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ein Layer aus Neuronen\n",
    "\n",
    "Wie in dem folgenden Bild zu sehen ist, besteht eine Schicht eines neuronalen Netzes immer aus mehreren Neuronen. Deswegen wollen wir im Folgenden eine Schicht eines neuronalen Netzes implementieren. Die Ausgabe des Layers wird dabei als Liste realisiert. Wie wir sehen werden, implementieren wir ein vollvernetztes neuronales Netz. Das bedeutet, dass die Inputs in einer Schicht von allen Neuronen mit ihren eigenen Gewichten aufgenommen werden.\n",
    "\n",
    "![](resources/neuralnet.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights1 = [0.2, 0.8, -0.5, 1]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "outputs = [\n",
    "    # Neuron 1:\n",
    "    inputs[0] * weights1[0] +\n",
    "    inputs[1] * weights1[1] +\n",
    "    inputs[2] * weights1[2] +\n",
    "    inputs[3] * weights1[3] +\n",
    "    bias1,\n",
    "\n",
    "    # Neuron 2:\n",
    "    inputs[0] * weights2[0] +\n",
    "    inputs[1] * weights2[1] +\n",
    "    inputs[2] * weights2[2] +\n",
    "    inputs[3] * weights2[3] +\n",
    "    bias2,\n",
    "\n",
    "    # Neuron 3:\n",
    "    inputs[0] * weights3[0] +\n",
    "    inputs[1] * weights3[1] +\n",
    "    inputs[2] * weights3[2] +\n",
    "    inputs[3] * weights3[3] +\n",
    "    bias3\n",
    "]\n",
    "\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.500003400Z",
     "start_time": "2023-06-21T13:31:45.819800300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Uvngs6sWyBg?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Uvngs6sWyBg?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.501003900Z",
     "start_time": "2023-06-21T13:31:45.875795900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Aufgabe 2:** Implementieren Sie den vorhergehenden Code mit Schleifen, sodass wir nicht mehr explizit auf die einzelnen Gewichte und Inputs zugreifen müssen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.501003900Z",
     "start_time": "2023-06-21T13:31:45.944879300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Aufgabe 3:** Gibt es noch eine einfachere Möglichkeit ein solches Netz zu implementieren?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensoren, Matrizen und Vektoren\n",
    "\n",
    "Richtig! Wir könnten das ganze auch mit Vektoren, Matrizen und Tensoren lösen. Wie das Ganze in Python aussieht werden wir im Folgenden sehen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/z_fcBg6_bKU?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/z_fcBg6_bKU?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.502006100Z",
     "start_time": "2023-06-21T13:31:45.970877400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "vector = [1,5,6,2]\n",
    "matrix = [[4,2],\n",
    "          [5,1],\n",
    "          [8,2]]\n",
    "tensor = [\n",
    "    [[1,5,6,2],\n",
    "     [3,2,1,3]],\n",
    "    [[5,2,1,2],\n",
    "     [6,4,8,4]],\n",
    "    [[2,8,5,3],\n",
    "     [1,1,9,4]]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.502006100Z",
     "start_time": "2023-06-21T13:31:46.024882300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alles wird einfacher mit numpy\n",
    "\n",
    "### Überblick numpy\n",
    "\n",
    "Im Folgenden werden wir `numpy` als Bibliothek verwenden, um mathematische Operationen auszufühen. Diese Bibliothek hat sich als \"Standard\" in Python durchgesetzt, weil sie einfach zu verwenden ist und effizient implementiert ist.\n",
    "\n",
    "Im Folgenden sollen die wichtigsten Funktionen aufgezählt werden:\n",
    "\n",
    "`numpy.log(x)` - natürlicher Logarithmus\n",
    "`numpy.sum(a)` - bildet die Summe eines Arrays\n",
    "`numpy.exp(x)` - berechnet die Exponentialfunktion aller Elemente\n",
    "`numpy.dot(a, b)` - Skalarprodukt zweier Arrays\n",
    "`numpy.matmul(x1, x2)` - Matrixprodukt zweier Arrays\n",
    "`a.T` - Transposes des Arrays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KBPvlUp-m5Y?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KBPvlUp-m5Y?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.522007500Z",
     "start_time": "2023-06-21T13:31:46.096882400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/D-zJAbTxwtg?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/D-zJAbTxwtg?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.523012700Z",
     "start_time": "2023-06-21T13:31:46.128880700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ein Neuron mit numpy\n",
    "\n",
    "Im Folgenden wird nun ein Neuron mit `numpy` umgesetzt. Dafür muss `numpy` aber erst mal importiert werden. Als \"Standard\" hat es sich dabei durchgesetzt `numpy` als alias `np` zu importieren, um Schreibaufwand zu sparen, auch wenn es sich dabei eigentlich um ein \"Code Smell\" handelt. (siehe Gang of Four \"Design Patterns\")\n",
    "\n",
    "Wie wir sehen könne Zugriffe auf die einzelnen Elemente durch das Skalarprodukt ersetzen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.529009500Z",
     "start_time": "2023-06-21T13:31:46.161881100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7ReqEO4U7Lc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7ReqEO4U7Lc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.529009500Z",
     "start_time": "2023-06-21T13:31:46.922007700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ein Layer mit numpy\n",
    "\n",
    "Das ganze können wir nun auch auf einen ganzen Layer erweitern. Wie wir sehen lässt sich auch das mit einem Skalarprodukt implementieren, wobei unsere Gewichte nun eine Matrix sind."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "\n",
    "print(layer_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.530008200Z",
     "start_time": "2023-06-21T13:31:46.946007600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Fhbcl0grca8?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; ncrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Fhbcl0grca8?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; ncrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.530008200Z",
     "start_time": "2023-06-21T13:31:46.979006800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Batch Daten\n",
    "\n",
    "Wenn wir später die neuronalen Netze zum Lernen verwenden, werden wir in der Regel nicht nach jedem einzelnen Datum ein Training, das heißt eine Anpassung der Gewichte durchführen, da dadurch das neuronale Netz zu sehr auf die einzelnen Daten trainiert werden würde. Stattdessen verwenden wir in der Regel Batches von Daten. Dadurch wird deren arithmetisches Mittel gelernt und unser neuronales Netz wird nicht zu sehr in eine bestimmte Richtung gedrängt.\n",
    "\n",
    "Wie sich herausstellt, wird dadurch aus unserem Input-Vektor (bisher war es ein Zeilenvektor) nun eine Matrix, die wir auch mittels dem Skalarprodukt aufmultipliziren können. Allerdings benötigen wir nun das Transpose der Gewichte."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iBCM3zkHXeo?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iBCM3zkHXeo?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.531007500Z",
     "start_time": "2023-06-21T13:31:46.996008900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "print(layer_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.531007500Z",
     "start_time": "2023-06-21T13:31:47.021008300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Erstellen weiterer Layer\n",
    "\n",
    "Da die neuronalen Netze nie ohne einen hidden-layer (siehe zweites Bild) auskommen müssen wir nun betrachten, wie wir mehrere Schichten verwenden können. Auch hier verwenden wir wieder das Skalarprodukt. Und genau wie es die schematische Abbildung zeigt, ist der Input des zweiten Layers der Output des ersten Layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5], [2., 5., -1., 2], [-1.5, 2.7, 3.3, -0.8]]\n",
    "weights = [[0.2, 0.8, -0.5, 1], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5], [-0.5, 0.12, -0.33], [-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:47.532007200Z",
     "start_time": "2023-06-21T13:31:47.053007800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ein erster Datensatz\n",
    "\n",
    "Nun wollen wir mit einem einfacheren Datensatz beginnen. Wir verwenden dazu das Spiral-Dataset, welches nur zwei Parameter hat und damit leichter veranschaulicht werden kann. Dabei sind die einzelnen Punkte einer von drei Klassen zugeordnet, was anhand der Farben zu erkennen ist. Insgesamt ist der Datensatz schwer zu lernen, weil wir nicht einfach eine gerade Linie ziehen können, um die Punkte der zweier Klassen voneinander zu trennen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install nnfs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='brg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:51.761782Z",
     "start_time": "2023-06-21T13:31:47.080008600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dense-Layer sind Klasse\n",
    "\n",
    "### Der Dense Layer\n",
    "\n",
    "Im Folgenden wird der bisherige Code in einer Klasse gebündelt. Klassen kann man sich als Schablonen oder Kochrezepte vorstellen. Sie selbst dienen nicht der Berechnung, wenn man dann aber einen z.B. Kuchen erstellt haben wir eine Anleitung wie dieser aussehen soll. **Sie müssen sich nicht weiter mit der Notation von Klassen auseinandersetzen. Wir verwenden diese hier nur, um im weiteren Verlauf ein einheitliches Framework aufzubauen.**\n",
    "\n",
    "Der Dense Layer ist, wie es der Name schon sagt, eine vollvernetzte Schicht. Da wir in der Regel keine Gewichte gegeben haben, müssen wir diese initial für jeden Layer selbst erstellen. Da es hier keine allgemeine Regel gibt, welche Gewichte die besten sind, verwenden wir einfach zufällige Zahlen.\n",
    "\n",
    "Unsere bisherigen Berechnungen sind der genannte \"forward pass\" eines neuronalen Netzes. Der Begriff wird besser verständlich, wenn wir uns später sein Gegenstück ansehen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-1.0475188e-04  1.1395361e-04 -4.7983500e-05]\n",
      " [-2.7414842e-04  3.1729150e-04 -8.6921798e-05]\n",
      " [-4.2188365e-04  5.2666257e-04 -5.5912682e-05]\n",
      " [-5.7707680e-04  7.1401405e-04 -8.9430439e-05]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Let's see output of the first few samples:\n",
    "print(dense1.output[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.024495100Z",
     "start_time": "2023-06-21T13:31:51.731774700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aktivierungsfunktionen\n",
    "\n",
    "Bereits im ersten Bild war eine Aktivierungsfunktion zu sehen. Diese Funktionen beschränken die Ausgabe auf einen bestimmten Wertebereich. Mit der *ReLU* Funktion kann z.B. dafür gesorgt werden, dass negative Werte auf $0$ gesetzt werden und somit das Neuron nicht \"feuert\". *Softmax* hingegen findet häufig Verwendung bei der letzten Ausgabeschicht eines Klassifikators. Außerdem sorgen nicht-lineare Aktivierungsfunktionen dafür, dass wir komplexe Daten lernen können.\n",
    "\n",
    "![](resources/activation-functions.png)\n",
    "Quelle: https://sefiks.com/2020/02/02/dance-moves-of-deep-learning-activation-functions/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/joA6fEAbAQc?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/joA6fEAbAQc?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.069030700Z",
     "start_time": "2023-06-21T13:31:51.884490500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from input\n",
    "        self.output = np.maximum(0, inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.078033300Z",
     "start_time": "2023-06-21T13:31:51.965492400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.255566400Z",
     "start_time": "2023-06-21T13:31:52.011495500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "# Create Softmax activation (to be used with Dense layer):\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "# Make a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Make a forward pass through activation function\n",
    "# it takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Make a forward pass through second Dense layer\n",
    "# it takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Make a forward pass through activation function\n",
    "# it takes the output of second dense layer here\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "\n",
    "# Let's see output of the first few samples:\n",
    "print(activation2.output[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.354567500Z",
     "start_time": "2023-06-21T13:31:52.053495400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training des neuronalen Netzes\n",
    "\n",
    "### Categorical Cross Entropy\n",
    "\n",
    "Um unser neuronales Netz trainieren zu können benötigen wir ein Maß wie gut oder schlecht es aktuell ist. Dafür verwenden wir in der Optimierung eine Zielfunktion oder Kostenfunktion. Im maschinellen Lernen heißt diese Funkion Loss-Funktion. In der linearen Regression verwenden wir hierzu häufig die quadrierten Fehler. Da wir hier nicht mit diskreten, sondern mit binären Werten arbeiten, verwenden wir die \"Categorical Cross Entropy\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "class Loss:\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # Return loss\n",
    "        return data_loss\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped*y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.403110100Z",
     "start_time": "2023-06-21T13:31:52.122031500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333412 0.3333327  0.33333313]\n",
      " [0.33333495 0.333332   0.33333302]\n",
      " [0.3333358  0.3333313  0.33333293]\n",
      " [0.33333617 0.33333114 0.3333327 ]]\n",
      "loss: 1.0986174\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "# Create Softmax activation (to be used with Dense layer):\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "# Create loss function\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# it takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "\n",
    "# Perform a forward pass through second Dense layer\n",
    "# it takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# it takes the output of second dense layer here\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "# Let's see output of the first few samples:\n",
    "print(activation2.output[:5])\n",
    "\n",
    "# Perform a forward pass through loss function\n",
    "# it takes the output of second dense layer here and returns loss\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "# Print loss value\n",
    "print('loss:', loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.406108600Z",
     "start_time": "2023-06-21T13:31:52.154030100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wie akkurat ist unser neuronales Netz\n",
    "\n",
    "Die Loss-funktion, deren Wert wir später minimieren wollen gibt uns jedoch noch keinen menschenlesbaren Wert wie gut unser Netz ist. Also wie häufig etwas z.B. richitg klassifiziert wird. Dafür verwenden wir die Akkuratheit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.31\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy from output of activation2 and targets\n",
    "# calculate values along first axis\n",
    "predictions = np.argmax(activation2.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y, axis=1)\n",
    "accuracy = np.mean(predictions == y)\n",
    "\n",
    "# Print accuracy\n",
    "print('acc:', accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.444107500Z",
     "start_time": "2023-06-21T13:31:52.211563300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ableitungen\n",
    "\n",
    "Mit der Loss-Funktion bewaffnet könnten wir theoretisch sehr leicht die optimalen Parameter herausfinden, indem wir einfach das globale Minimum suchen. Hierfür brauchen wir die erste und zweite Ableitung: [https://www.studysmarter.de/schule/mathe/analysis/globale-extrema/](https://www.studysmarter.de/schule/mathe/analysis/globale-extrema/)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2zdlQ0MaXBw?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2zdlQ0MaXBw?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.717116900Z",
     "start_time": "2023-06-21T13:31:52.278562900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backpropagation\n",
    "\n",
    "Bei unseren neuronalen Netzen ist es allerdings nicht mehr möglich die kompletten Ableitungen zu berechnen um somit lokale und globale Minima zu finden. Stattdessen verwenden wir partielle Ableitungen, um mithilfe der Backpropagation einen Weg zu einer besseren Lösung zu finden. Mithilfe des Gradientenabstiegs können wir dann Schritt für Schritt zu einem optimalen Minimum gelangen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/_9qHQA30hys?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/_9qHQA30hys?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:52.719112100Z",
     "start_time": "2023-06-21T13:31:52.307561200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.3333332  0.3333332  0.33333364]\n",
      " [0.3333329  0.33333293 0.3333342 ]\n",
      " [0.3333326  0.33333263 0.33333477]\n",
      " [0.33333233 0.3333324  0.33333528]]\n",
      "loss: 1.0986104\n",
      "acc: 0.34\n",
      "[[ 1.5766357e-04  7.8368583e-05  4.7324400e-05]\n",
      " [ 1.8161038e-04  1.1045573e-05 -3.3096312e-05]]\n",
      "[[-3.60553473e-04  9.66117223e-05 -1.03671395e-04]]\n",
      "[[ 5.44109462e-05  1.07411419e-04 -1.61822361e-04]\n",
      " [-4.07913431e-05 -7.16780924e-05  1.12469446e-04]\n",
      " [-5.30112993e-05  8.58172934e-05 -3.28059905e-05]]\n",
      "[[-1.0729185e-05 -9.4610732e-06  2.0027859e-05]]\n"
     ]
    }
   ],
   "source": [
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in \\\n",
    "                enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                              np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)\n",
    "\n",
    "\n",
    "# Common loss class\n",
    "class Loss:\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # Return loss\n",
    "        return data_loss\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Perform a forward pass through second Dense layer\n",
    "# takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Perform a forward pass through the activation/loss function\n",
    "# takes the output of second dense layer here and returns loss\n",
    "loss = loss_activation.forward(dense2.output, y)\n",
    "# Let's see output of the first few samples:\n",
    "print(loss_activation.output[:5])\n",
    "\n",
    "# Print loss value\n",
    "print('loss:', loss)\n",
    "\n",
    "# Calculate accuracy from output of activation2 and targets\n",
    "# calculate values along first axis\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y, axis=1)\n",
    "accuracy = np.mean(predictions==y)\n",
    "\n",
    "# Print accuracy\n",
    "print('acc:', accuracy)\n",
    "\n",
    "# Backward pass\n",
    "loss_activation.backward(loss_activation.output, y)\n",
    "dense2.backward(loss_activation.dinputs)\n",
    "activation1.backward(dense2.dinputs)\n",
    "dense1.backward(activation1.dinputs)\n",
    "\n",
    "# Print gradients\n",
    "print(dense1.dweights)\n",
    "print(dense1.dbiases)\n",
    "print(dense2.dweights)\n",
    "print(dense2.dbiases)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:53.047930200Z",
     "start_time": "2023-06-21T13:31:52.349563900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "Zum Optimieren unserer Kostenfunktionen wollen wir nun die Funktion Stochastic Gradient Descent einführen. Es handelt sich dabei um den vorher angesprochenen Gradientenabstieg, also das schrittweise gehen in Richtung des Minimums anand des aktuellen Anstiegs. Um etwas feingranularer in eine bestimmte Richtung gehen zu können verwenden wir die Lernrate. Diese gibt wie stark wir in Richtung des Abstiegs gehen. Dabei ist die Verwendung einer guten Lernrate sehr wichtig, wobei die optimale Lernrate nicht universal ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/B4qIVGwky4c?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/B4qIVGwky4c?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:53.276926600Z",
     "start_time": "2023-06-21T13:31:52.676110800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CeCBgQXb8Sw?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CeCBgQXb8Sw?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:53.277926700Z",
     "start_time": "2023-06-21T13:31:52.743798600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/37xsHIH7q3c?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/37xsHIH7q3c?controls=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:53.279927Z",
     "start_time": "2023-06-21T13:31:52.788929500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# SGD optimizer\n",
    "class Optimizer_SGD:\n",
    "\n",
    "    # Initialize optimizer - set settings,\n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        weight_updates = -self.current_learning_rate * \\\n",
    "                         layer.dweights\n",
    "        bias_updates = -self.current_learning_rate * \\\n",
    "                       layer.dbiases\n",
    "\n",
    "        # Update weights and biases using either\n",
    "        # vanilla or momentum updates\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:31:53.397930900Z",
     "start_time": "2023-06-21T13:31:52.824927600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.347, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.407, loss: 1.070, lr: 1.0\n",
      "epoch: 200, acc: 0.410, loss: 1.064, lr: 1.0\n",
      "epoch: 300, acc: 0.427, loss: 1.061, lr: 1.0\n",
      "epoch: 400, acc: 0.420, loss: 1.059, lr: 1.0\n",
      "epoch: 500, acc: 0.420, loss: 1.056, lr: 1.0\n",
      "epoch: 600, acc: 0.420, loss: 1.052, lr: 1.0\n",
      "epoch: 700, acc: 0.433, loss: 1.043, lr: 1.0\n",
      "epoch: 800, acc: 0.453, loss: 1.029, lr: 1.0\n",
      "epoch: 900, acc: 0.503, loss: 1.014, lr: 1.0\n",
      "epoch: 1000, acc: 0.450, loss: 1.018, lr: 1.0\n",
      "epoch: 1100, acc: 0.460, loss: 1.013, lr: 1.0\n",
      "epoch: 1200, acc: 0.437, loss: 1.007, lr: 1.0\n",
      "epoch: 1300, acc: 0.453, loss: 1.005, lr: 1.0\n",
      "epoch: 1400, acc: 0.420, loss: 1.002, lr: 1.0\n",
      "epoch: 1500, acc: 0.450, loss: 0.990, lr: 1.0\n",
      "epoch: 1600, acc: 0.443, loss: 0.996, lr: 1.0\n",
      "epoch: 1700, acc: 0.487, loss: 0.983, lr: 1.0\n",
      "epoch: 1800, acc: 0.470, loss: 0.972, lr: 1.0\n",
      "epoch: 1900, acc: 0.473, loss: 0.964, lr: 1.0\n",
      "epoch: 2000, acc: 0.500, loss: 0.952, lr: 1.0\n",
      "epoch: 2100, acc: 0.490, loss: 0.945, lr: 1.0\n",
      "epoch: 2200, acc: 0.517, loss: 0.943, lr: 1.0\n",
      "epoch: 2300, acc: 0.517, loss: 0.925, lr: 1.0\n",
      "epoch: 2400, acc: 0.533, loss: 0.923, lr: 1.0\n",
      "epoch: 2500, acc: 0.520, loss: 0.908, lr: 1.0\n",
      "epoch: 2600, acc: 0.537, loss: 0.900, lr: 1.0\n",
      "epoch: 2700, acc: 0.553, loss: 0.872, lr: 1.0\n",
      "epoch: 2800, acc: 0.540, loss: 0.859, lr: 1.0\n",
      "epoch: 2900, acc: 0.583, loss: 0.844, lr: 1.0\n",
      "epoch: 3000, acc: 0.600, loss: 0.838, lr: 1.0\n",
      "epoch: 3100, acc: 0.607, loss: 0.845, lr: 1.0\n",
      "epoch: 3200, acc: 0.567, loss: 0.977, lr: 1.0\n",
      "epoch: 3300, acc: 0.583, loss: 0.896, lr: 1.0\n",
      "epoch: 3400, acc: 0.597, loss: 0.859, lr: 1.0\n",
      "epoch: 3500, acc: 0.607, loss: 0.835, lr: 1.0\n",
      "epoch: 3600, acc: 0.600, loss: 0.852, lr: 1.0\n",
      "epoch: 3700, acc: 0.580, loss: 0.862, lr: 1.0\n",
      "epoch: 3800, acc: 0.597, loss: 0.816, lr: 1.0\n",
      "epoch: 3900, acc: 0.660, loss: 0.746, lr: 1.0\n",
      "epoch: 4000, acc: 0.527, loss: 0.901, lr: 1.0\n",
      "epoch: 4100, acc: 0.617, loss: 0.805, lr: 1.0\n",
      "epoch: 4200, acc: 0.683, loss: 0.710, lr: 1.0\n",
      "epoch: 4300, acc: 0.650, loss: 0.707, lr: 1.0\n",
      "epoch: 4400, acc: 0.613, loss: 0.792, lr: 1.0\n",
      "epoch: 4500, acc: 0.640, loss: 0.743, lr: 1.0\n",
      "epoch: 4600, acc: 0.650, loss: 0.734, lr: 1.0\n",
      "epoch: 4700, acc: 0.637, loss: 0.801, lr: 1.0\n",
      "epoch: 4800, acc: 0.650, loss: 0.733, lr: 1.0\n",
      "epoch: 4900, acc: 0.667, loss: 0.706, lr: 1.0\n",
      "epoch: 5000, acc: 0.680, loss: 0.677, lr: 1.0\n",
      "epoch: 5100, acc: 0.693, loss: 0.668, lr: 1.0\n",
      "epoch: 5200, acc: 0.680, loss: 0.671, lr: 1.0\n",
      "epoch: 5300, acc: 0.683, loss: 0.650, lr: 1.0\n",
      "epoch: 5400, acc: 0.683, loss: 0.672, lr: 1.0\n",
      "epoch: 5500, acc: 0.663, loss: 0.738, lr: 1.0\n",
      "epoch: 5600, acc: 0.697, loss: 0.645, lr: 1.0\n",
      "epoch: 5700, acc: 0.687, loss: 0.643, lr: 1.0\n",
      "epoch: 5800, acc: 0.553, loss: 0.973, lr: 1.0\n",
      "epoch: 5900, acc: 0.697, loss: 0.629, lr: 1.0\n",
      "epoch: 6000, acc: 0.700, loss: 0.635, lr: 1.0\n",
      "epoch: 6100, acc: 0.490, loss: 1.333, lr: 1.0\n",
      "epoch: 6200, acc: 0.710, loss: 0.626, lr: 1.0\n",
      "epoch: 6300, acc: 0.707, loss: 0.625, lr: 1.0\n",
      "epoch: 6400, acc: 0.643, loss: 0.751, lr: 1.0\n",
      "epoch: 6500, acc: 0.707, loss: 0.625, lr: 1.0\n",
      "epoch: 6600, acc: 0.710, loss: 0.617, lr: 1.0\n",
      "epoch: 6700, acc: 0.707, loss: 0.631, lr: 1.0\n",
      "epoch: 6800, acc: 0.697, loss: 0.651, lr: 1.0\n",
      "epoch: 6900, acc: 0.713, loss: 0.618, lr: 1.0\n",
      "epoch: 7000, acc: 0.703, loss: 0.632, lr: 1.0\n",
      "epoch: 7100, acc: 0.697, loss: 0.640, lr: 1.0\n",
      "epoch: 7200, acc: 0.713, loss: 0.606, lr: 1.0\n",
      "epoch: 7300, acc: 0.690, loss: 0.663, lr: 1.0\n",
      "epoch: 7400, acc: 0.707, loss: 0.606, lr: 1.0\n",
      "epoch: 7500, acc: 0.710, loss: 0.612, lr: 1.0\n",
      "epoch: 7600, acc: 0.710, loss: 0.616, lr: 1.0\n",
      "epoch: 7700, acc: 0.710, loss: 0.604, lr: 1.0\n",
      "epoch: 7800, acc: 0.703, loss: 0.628, lr: 1.0\n",
      "epoch: 7900, acc: 0.710, loss: 0.603, lr: 1.0\n",
      "epoch: 8000, acc: 0.707, loss: 0.616, lr: 1.0\n",
      "epoch: 8100, acc: 0.710, loss: 0.605, lr: 1.0\n",
      "epoch: 8200, acc: 0.710, loss: 0.617, lr: 1.0\n",
      "epoch: 8300, acc: 0.710, loss: 0.626, lr: 1.0\n",
      "epoch: 8400, acc: 0.707, loss: 0.603, lr: 1.0\n",
      "epoch: 8500, acc: 0.463, loss: 1.761, lr: 1.0\n",
      "epoch: 8600, acc: 0.720, loss: 0.591, lr: 1.0\n",
      "epoch: 8700, acc: 0.713, loss: 0.604, lr: 1.0\n",
      "epoch: 8800, acc: 0.697, loss: 0.660, lr: 1.0\n",
      "epoch: 8900, acc: 0.723, loss: 0.588, lr: 1.0\n",
      "epoch: 9000, acc: 0.717, loss: 0.593, lr: 1.0\n",
      "epoch: 9100, acc: 0.670, loss: 0.720, lr: 1.0\n",
      "epoch: 9200, acc: 0.713, loss: 0.594, lr: 1.0\n",
      "epoch: 9300, acc: 0.723, loss: 0.585, lr: 1.0\n",
      "epoch: 9400, acc: 0.727, loss: 0.598, lr: 1.0\n",
      "epoch: 9500, acc: 0.673, loss: 0.723, lr: 1.0\n",
      "epoch: 9600, acc: 0.730, loss: 0.579, lr: 1.0\n",
      "epoch: 9700, acc: 0.713, loss: 0.588, lr: 1.0\n",
      "epoch: 9800, acc: 0.723, loss: 0.581, lr: 1.0\n",
      "epoch: 9900, acc: 0.727, loss: 0.591, lr: 1.0\n",
      "epoch: 10000, acc: 0.723, loss: 0.595, lr: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD()\n",
    "\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "\n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {loss:.3f}, ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:32:18.432415700Z",
     "start_time": "2023-06-21T13:31:52.896928800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Aufgabe 4:** Testen Sie verschiedener Lernraten!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.367, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.413, loss: 1.063, lr: 0.9099181073703367\n",
      "epoch: 200, acc: 0.413, loss: 1.061, lr: 0.8340283569641367\n",
      "epoch: 300, acc: 0.423, loss: 1.060, lr: 0.7698229407236336\n",
      "epoch: 400, acc: 0.410, loss: 1.057, lr: 0.7147962830593281\n",
      "epoch: 500, acc: 0.427, loss: 1.052, lr: 0.66711140760507\n",
      "epoch: 600, acc: 0.440, loss: 1.036, lr: 0.6253908692933083\n",
      "epoch: 700, acc: 0.473, loss: 1.009, lr: 0.5885815185403178\n",
      "epoch: 800, acc: 0.523, loss: 0.975, lr: 0.5558643690939411\n",
      "epoch: 900, acc: 0.520, loss: 0.967, lr: 0.526592943654555\n",
      "epoch: 1000, acc: 0.473, loss: 0.963, lr: 0.5002501250625312\n",
      "epoch: 1100, acc: 0.477, loss: 0.953, lr: 0.4764173415912339\n",
      "epoch: 1200, acc: 0.480, loss: 0.948, lr: 0.45475216007276037\n",
      "epoch: 1300, acc: 0.497, loss: 0.940, lr: 0.43497172683775553\n",
      "epoch: 1400, acc: 0.513, loss: 0.931, lr: 0.4168403501458941\n",
      "epoch: 1500, acc: 0.520, loss: 0.927, lr: 0.4001600640256102\n",
      "epoch: 1600, acc: 0.507, loss: 0.917, lr: 0.3847633705271258\n",
      "epoch: 1700, acc: 0.547, loss: 0.934, lr: 0.3705075954057058\n",
      "epoch: 1800, acc: 0.513, loss: 0.887, lr: 0.35727045373347627\n",
      "epoch: 1900, acc: 0.513, loss: 0.916, lr: 0.3449465332873405\n",
      "epoch: 2000, acc: 0.577, loss: 0.909, lr: 0.33344448149383127\n",
      "epoch: 2100, acc: 0.497, loss: 0.922, lr: 0.32268473701193934\n",
      "epoch: 2200, acc: 0.547, loss: 0.900, lr: 0.31259768677711786\n",
      "epoch: 2300, acc: 0.520, loss: 0.853, lr: 0.3031221582297666\n",
      "epoch: 2400, acc: 0.523, loss: 0.883, lr: 0.29420417769932333\n",
      "epoch: 2500, acc: 0.570, loss: 0.881, lr: 0.2857959416976279\n",
      "epoch: 2600, acc: 0.540, loss: 0.840, lr: 0.2778549597110308\n",
      "epoch: 2700, acc: 0.543, loss: 0.860, lr: 0.2703433360367667\n",
      "epoch: 2800, acc: 0.560, loss: 0.858, lr: 0.26322716504343247\n",
      "epoch: 2900, acc: 0.600, loss: 0.867, lr: 0.25647601949217746\n",
      "epoch: 3000, acc: 0.567, loss: 0.822, lr: 0.25006251562890724\n",
      "epoch: 3100, acc: 0.573, loss: 0.816, lr: 0.2439619419370578\n",
      "epoch: 3200, acc: 0.603, loss: 0.827, lr: 0.23815194093831865\n",
      "epoch: 3300, acc: 0.617, loss: 0.827, lr: 0.23261223540358225\n",
      "epoch: 3400, acc: 0.613, loss: 0.816, lr: 0.22732439190725165\n",
      "epoch: 3500, acc: 0.600, loss: 0.804, lr: 0.22227161591464767\n",
      "epoch: 3600, acc: 0.597, loss: 0.786, lr: 0.21743857360295715\n",
      "epoch: 3700, acc: 0.650, loss: 0.820, lr: 0.21281123643328367\n",
      "epoch: 3800, acc: 0.613, loss: 0.803, lr: 0.20837674515524068\n",
      "epoch: 3900, acc: 0.623, loss: 0.780, lr: 0.20412329046744235\n",
      "epoch: 4000, acc: 0.630, loss: 0.783, lr: 0.2000400080016003\n",
      "epoch: 4100, acc: 0.613, loss: 0.762, lr: 0.19611688566385566\n",
      "epoch: 4200, acc: 0.613, loss: 0.775, lr: 0.19234468166955185\n",
      "epoch: 4300, acc: 0.643, loss: 0.773, lr: 0.18871485185884126\n",
      "epoch: 4400, acc: 0.647, loss: 0.754, lr: 0.18521948508983144\n",
      "epoch: 4500, acc: 0.643, loss: 0.764, lr: 0.18185124568103292\n",
      "epoch: 4600, acc: 0.647, loss: 0.757, lr: 0.1786033220217896\n",
      "epoch: 4700, acc: 0.650, loss: 0.724, lr: 0.1754693805930865\n",
      "epoch: 4800, acc: 0.640, loss: 0.733, lr: 0.17244352474564578\n",
      "epoch: 4900, acc: 0.677, loss: 0.719, lr: 0.16952025767079165\n",
      "epoch: 5000, acc: 0.647, loss: 0.730, lr: 0.16669444907484582\n",
      "epoch: 5100, acc: 0.673, loss: 0.710, lr: 0.16396130513198884\n",
      "epoch: 5200, acc: 0.657, loss: 0.723, lr: 0.16131634134537828\n",
      "epoch: 5300, acc: 0.683, loss: 0.697, lr: 0.15875535799333226\n",
      "epoch: 5400, acc: 0.667, loss: 0.699, lr: 0.1562744178777934\n",
      "epoch: 5500, acc: 0.690, loss: 0.688, lr: 0.15386982612709646\n",
      "epoch: 5600, acc: 0.710, loss: 0.703, lr: 0.15153811183512653\n",
      "epoch: 5700, acc: 0.690, loss: 0.704, lr: 0.14927601134497687\n",
      "epoch: 5800, acc: 0.713, loss: 0.667, lr: 0.14708045300779526\n",
      "epoch: 5900, acc: 0.690, loss: 0.660, lr: 0.14494854326714016\n",
      "epoch: 6000, acc: 0.690, loss: 0.648, lr: 0.1428775539362766\n",
      "epoch: 6100, acc: 0.730, loss: 0.639, lr: 0.1408649105507818\n",
      "epoch: 6200, acc: 0.687, loss: 0.687, lr: 0.13890818169190167\n",
      "epoch: 6300, acc: 0.720, loss: 0.646, lr: 0.13700506918755992\n",
      "epoch: 6400, acc: 0.733, loss: 0.621, lr: 0.13515339910798757\n",
      "epoch: 6500, acc: 0.707, loss: 0.652, lr: 0.13335111348179757\n",
      "epoch: 6600, acc: 0.727, loss: 0.631, lr: 0.13159626266614027\n",
      "epoch: 6700, acc: 0.737, loss: 0.606, lr: 0.12988699831146902\n",
      "epoch: 6800, acc: 0.740, loss: 0.588, lr: 0.12822156686754713\n",
      "epoch: 6900, acc: 0.730, loss: 0.610, lr: 0.126598303582732\n",
      "epoch: 7000, acc: 0.717, loss: 0.614, lr: 0.12501562695336915\n",
      "epoch: 7100, acc: 0.727, loss: 0.589, lr: 0.12347203358439313\n",
      "epoch: 7200, acc: 0.723, loss: 0.596, lr: 0.12196609342602757\n",
      "epoch: 7300, acc: 0.763, loss: 0.566, lr: 0.12049644535486204\n",
      "epoch: 7400, acc: 0.777, loss: 0.560, lr: 0.11906179307060363\n",
      "epoch: 7500, acc: 0.777, loss: 0.562, lr: 0.11766090128250381\n",
      "epoch: 7600, acc: 0.753, loss: 0.558, lr: 0.11629259216187929\n",
      "epoch: 7700, acc: 0.747, loss: 0.568, lr: 0.11495574203931487\n",
      "epoch: 7800, acc: 0.747, loss: 0.550, lr: 0.11364927832708263\n",
      "epoch: 7900, acc: 0.757, loss: 0.535, lr: 0.11237217664906168\n",
      "epoch: 8000, acc: 0.770, loss: 0.542, lr: 0.11112345816201799\n",
      "epoch: 8100, acc: 0.780, loss: 0.512, lr: 0.10990218705352237\n",
      "epoch: 8200, acc: 0.787, loss: 0.522, lr: 0.10870746820306555\n",
      "epoch: 8300, acc: 0.793, loss: 0.511, lr: 0.1075384449940854\n",
      "epoch: 8400, acc: 0.793, loss: 0.502, lr: 0.10639429726566654\n",
      "epoch: 8500, acc: 0.813, loss: 0.490, lr: 0.10527423939362038\n",
      "epoch: 8600, acc: 0.827, loss: 0.486, lr: 0.10417751849150952\n",
      "epoch: 8700, acc: 0.823, loss: 0.478, lr: 0.10310341272296113\n",
      "epoch: 8800, acc: 0.830, loss: 0.474, lr: 0.1020512297173181\n",
      "epoch: 8900, acc: 0.823, loss: 0.472, lr: 0.10102030508132134\n",
      "epoch: 9000, acc: 0.810, loss: 0.469, lr: 0.1000100010001\n",
      "epoch: 9100, acc: 0.807, loss: 0.462, lr: 0.09901970492127933\n",
      "epoch: 9200, acc: 0.817, loss: 0.455, lr: 0.09804882831650162\n",
      "epoch: 9300, acc: 0.827, loss: 0.450, lr: 0.09709680551509856\n",
      "epoch: 9400, acc: 0.833, loss: 0.444, lr: 0.09616309260505818\n",
      "epoch: 9500, acc: 0.837, loss: 0.439, lr: 0.09524716639679968\n",
      "epoch: 9600, acc: 0.837, loss: 0.435, lr: 0.09434852344560807\n",
      "epoch: 9700, acc: 0.847, loss: 0.430, lr: 0.09346667912889055\n",
      "epoch: 9800, acc: 0.843, loss: 0.426, lr: 0.09260116677470137\n",
      "epoch: 9900, acc: 0.853, loss: 0.421, lr: 0.09175153683824203\n",
      "epoch: 10000, acc: 0.850, loss: 0.417, lr: 0.09091735612328393\n"
     ]
    }
   ],
   "source": [
    "class Optimizer_SGD:\n",
    "\n",
    "    # Initialize optimizer - set settings,\n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If we use momentum\n",
    "        if self.momentum:\n",
    "\n",
    "            # If layer does not contain momentum arrays, create them\n",
    "            # filled with zeros\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                # If there is no momentum array for weights\n",
    "                # The array doesn't exist for biases yet either.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            # Build weight updates with momentum - take previous\n",
    "            # updates multiplied by retain factor and update with\n",
    "            # current gradients\n",
    "            weight_updates = \\\n",
    "                self.momentum * layer.weight_momentums - \\\n",
    "                self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            # Build bias updates\n",
    "            bias_updates = \\\n",
    "                self.momentum * layer.bias_momentums - \\\n",
    "                self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        # Vanilla SGD updates (as before momentum update)\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * \\\n",
    "                             layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * \\\n",
    "                           layer.dbiases\n",
    "\n",
    "        # Update weights and biases using either\n",
    "        # vanilla or momentum updates\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 64 output values\n",
    "dense1 = Layer_Dense(2, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD(decay=1e-3, momentum=0.5)\n",
    "\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "\n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {loss:.3f}, ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:32:31.411302400Z",
     "start_time": "2023-06-21T13:32:18.439418200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lernen des MNIST-Datensatzes\n",
    "\n",
    "Im Folgenden wollen wir uns mit dem MNIST Datensatz auseinandersetzen. Dafür werden wir zuerst die Daten in eine Form bringen, die unseren vorherigen entspricht."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import keras\n",
    "\n",
    "num_classes = 10\n",
    "(X, Y), _ = mnist.load_data()\n",
    "\n",
    "X = X.astype(\"float32\") / 255\n",
    "X = X.reshape(60000, 784)\n",
    "\n",
    "Y = keras.utils.to_categorical(Y, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:32:38.915074200Z",
     "start_time": "2023-06-21T13:32:31.423303300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](resources/mnist.jpg)\n",
    "Quelle: https://sefiks.com/2018/08/15/from-neural-networks-to-deep-learning/\n",
    "\n",
    "Nun wollen wir noch zwei Hilfsfunktionen definieren. Zum einen die Funktion `get_batch`, die uns immer 128 zufällige Werte aus dem neuronalen Netz gibt und `show_sample`, die uns hilft das Bild für eines Inputs anzuzeigen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "    idx = np.random.randint(60000, size=128)\n",
    "    return X[idx, :], Y[idx, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:32:38.927086700Z",
     "start_time": "2023-06-21T13:32:38.920081500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_sample(x):\n",
    "    plt.imshow(x.reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:32:38.989108100Z",
     "start_time": "2023-06-21T13:32:38.931083100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun verwenden wir die Klassen, die wir vorher bereits definiert haben, um ein neuronales Netz für unser neues Problem zu implementieren."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.109, loss: 2.300, lr: 1.0\n",
      "epoch: 100, acc: 0.938, loss: 0.215, lr: 0.9099181073703367\n",
      "epoch: 200, acc: 0.969, loss: 0.090, lr: 0.8340283569641367\n",
      "epoch: 300, acc: 0.984, loss: 0.058, lr: 0.7698229407236336\n",
      "epoch: 400, acc: 0.969, loss: 0.112, lr: 0.7147962830593281\n",
      "epoch: 500, acc: 0.961, loss: 0.079, lr: 0.66711140760507\n",
      "epoch: 600, acc: 0.969, loss: 0.102, lr: 0.6253908692933083\n",
      "epoch: 700, acc: 0.984, loss: 0.053, lr: 0.5885815185403178\n"
     ]
    }
   ],
   "source": [
    "# Create Dense layer with 784 input features and 10000 output values\n",
    "dense1 = Layer_Dense(784, 10000)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 10000 input features (as we take output\n",
    "# of previous layer here) and 10 output values (output values)\n",
    "dense2 = Layer_Dense(10000, 10)\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_SGD(decay=1e-3, momentum=0.5)\n",
    "\n",
    "# Train in loop\n",
    "for epoch in range(701):\n",
    "    x, y = get_batch()\n",
    "\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(x)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "\n",
    "    # Perform a forward pass through the activation/loss function\n",
    "    # takes the output of second dense layer here and returns loss\n",
    "    loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {loss:.3f}, ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward pass\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:39:20.179041400Z",
     "start_time": "2023-06-21T13:32:38.951077700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "x = X[[1], :]\n",
    "y = Y[[1], :]\n",
    "\n",
    "dense1.forward(x)\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Perform a forward pass through second Dense layer\n",
    "# takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Perform a forward pass through the activation/loss function\n",
    "# takes the output of second dense layer here and returns loss\n",
    "loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "# Calculate accuracy from output of activation2 and targets\n",
    "# calculate values along first axis\n",
    "predictions = np.argmax(loss_activation.output, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:39:20.265049600Z",
     "start_time": "2023-06-21T13:39:20.186041200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0], dtype=int64)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:39:20.290046700Z",
     "start_time": "2023-06-21T13:39:20.270039800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in x:\n",
    "    show_sample(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T13:39:20.408040700Z",
     "start_time": "2023-06-21T13:39:20.288039800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie wir sehen, haben wir ein Framework für neuronale Netze geschrieben. In der nächsten Session wollen wir ein fertiges populäres Framework verwenden, um weitere neuronale Netze zu implementiern."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
